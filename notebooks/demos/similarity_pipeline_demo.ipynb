{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d282e6",
   "metadata": {},
   "source": [
    "# Similarity Pipeline Demo\n",
    "\n",
    "This notebook demonstrates how to assemble the similarity pipeline components shipped with `spark-fuse` to cluster semantically similar rows and select per-cluster representatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d3977c",
   "metadata": {},
   "source": [
    "## 1. Start a local Spark session\n",
    "\n",
    "For demonstration purposes the session runs in local mode. In production you would rely on your existing cluster settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfbc7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook kernel: /Users/kevin/Github/spark-fuse/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "print(\"notebook kernel:\", sys.executable)\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/Users/kevin/Github/spark-fuse/.venv/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = os.environ[\"PYSPARK_PYTHON\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd17207c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYSPARK_PYTHON: /Users/kevin/Github/spark-fuse/.venv/bin/python\n",
      "PYSPARK_DRIVER_PYTHON: /Users/kevin/Github/spark-fuse/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('PYSPARK_PYTHON:', os.environ.get('PYSPARK_PYTHON'))\n",
    "print('PYSPARK_DRIVER_PYTHON:', os.environ.get('PYSPARK_DRIVER_PYTHON'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d367651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/kevin/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/kevin/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f3b9d3c8-c406-46ac-afb3-ff146c8b8710;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-storage;3.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 207ms :: artifacts dl 31ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f3b9d3c8-c406-46ac-afb3-ff146c8b8710\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/23ms)\n",
      "25/10/30 14:54:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from spark_fuse.spark import create_session\n",
    "\n",
    "spark = create_session(app_name=\"spark-fuse-similarity-demo\", master=\"local[2]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00040ce2",
   "metadata": {},
   "source": [
    "## 2. Create a sample dataset\n",
    "\n",
    "Each row carries a simple three-dimensional embedding and a quality score that we can later use to pick representatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9598a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+-----+\n",
      "|product_id|description            |score|\n",
      "+----------+-----------------------+-----+\n",
      "|1         |Crunchy Red Apple      |4.7  |\n",
      "|2         |Sweet Gala Apple       |4.9  |\n",
      "|3         |Fresh Cavendish Banana |4.6  |\n",
      "|4         |Ripe Plantain          |4.5  |\n",
      "|5         |Classic Spiral Notebook|4.4  |\n",
      "+----------+-----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Crunchy Red Apple\", 4.7),\n",
    "    (2, \"Sweet Gala Apple\", 4.9),\n",
    "    (3, \"Fresh Cavendish Banana\", 4.6),\n",
    "    (4, \"Ripe Plantain\", 4.5),\n",
    "    (5, \"Classic Spiral Notebook\", 4.4),\n",
    "]\n",
    "columns = [\"product_id\", \"description\", \"score\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f0fc7",
   "metadata": {},
   "source": [
    "## 3. Configure and run the similarity pipeline\n",
    "\n",
    "The pipeline embeds the product descriptions with Hugging Face `sentence-transformers`, normalizes vectors for cosine similarity, clusters with K-Means, and keeps the highest scoring item per cluster. If the dependency is missing in your environment, the generator falls back to a deterministic stub so the demo continues to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14788a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Github/spark-fuse/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "25/10/30 14:55:08 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------------+\n",
      "|product_id|cluster_id|description            |\n",
      "+----------+----------+-----------------------+\n",
      "|3         |0         |Fresh Cavendish Banana |\n",
      "|4         |0         |Ripe Plantain          |\n",
      "|1         |1         |Crunchy Red Apple      |\n",
      "|2         |1         |Sweet Gala Apple       |\n",
      "|5         |2         |Classic Spiral Notebook|\n",
      "+----------+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spark_fuse.similarity import (\n",
    "    CosineSimilarity,\n",
    "    KMeansPartitioner,\n",
    "    MaxColumnChoice,\n",
    "    SentenceEmbeddingGenerator,\n",
    "    SimilarityPipeline,\n",
    ")\n",
    "\n",
    "embedding_generator = SentenceEmbeddingGenerator(\n",
    "    input_col=\"description\",\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    normalize=True,\n",
    "    use_vectorized=False,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "metric = CosineSimilarity(embedding_col=\"embedding\")\n",
    "partitioner = KMeansPartitioner(k=3, seed=7)\n",
    "choice = MaxColumnChoice(column=\"score\")\n",
    "\n",
    "pipeline = SimilarityPipeline(\n",
    "    embedding_generator=embedding_generator,\n",
    "    partitioner=partitioner,\n",
    "    similarity_metric=metric,\n",
    "    choice_function=choice,\n",
    ")\n",
    "\n",
    "clustered_df = pipeline.run(df)\n",
    "clustered_df.select(\"product_id\", \"cluster_id\", \"description\").orderBy(\"cluster_id\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53a903",
   "metadata": {},
   "source": [
    "## 4. Retrieve representatives\n",
    "\n",
    "With `MaxColumnChoice` the representative is simply the row with the largest score inside each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fedc6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------------+-----+\n",
      "|cluster_id|product_id|description            |score|\n",
      "+----------+----------+-----------------------+-----+\n",
      "|0         |3         |Fresh Cavendish Banana |4.6  |\n",
      "|1         |2         |Sweet Gala Apple       |4.9  |\n",
      "|2         |5         |Classic Spiral Notebook|4.4  |\n",
      "+----------+----------+-----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "representatives = pipeline.select_representatives(clustered_df)\n",
    "representatives.select(\"cluster_id\", \"product_id\", \"description\", \"score\").orderBy(\"cluster_id\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66df5a2d",
   "metadata": {},
   "source": [
    "## 5. Shut down Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1065f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
