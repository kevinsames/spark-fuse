{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Mapping Notebook Template\n",
    "\n",
    "Use this scaffold to normalize free-form values into canonical targets with `map_column_with_llm`.\n",
    "It includes logging, dry-run safety checks, and an optional persistence step.\n"
   ],
   "id": "bb47a4e9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook guidelines\n",
    "\n",
    "- Name notebooks in clear snake_case and keep one mapping target per notebook.\n",
    "- Start in dry-run mode to estimate coverage and cost before enabling live LLM calls.\n",
    "- Keep target values short and stable; treat them as the canonical vocabulary.\n",
    "- Avoid logging secrets; rely on environment variables or secret scopes.\n",
    "- Make runs idempotent with deterministic transforms and safe overwrite logic.\n"
   ],
   "id": "b3b11c2a"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from app.config.settings import get_settings\n\nimport datetime as _dt\n\nfrom pyspark.sql import Row, functions as F\n\nfrom spark_fuse.spark import create_session\nfrom spark_fuse.utils.dataframe import ensure_columns, preview\nfrom spark_fuse.utils.progress import (\n    console,\n    create_progress_tracker,\n    enable_spark_logging,\n    log_end as log_end_step,\n    log_error as log_error_step,\n    log_info as log_info_step,\n    log_warn as log_warn_step,\n)\nfrom spark_fuse.utils.llm import map_column_with_llm\n\nprogress_tracker = create_progress_tracker(total_steps=9)\nlog = console()\nSHOW_HTML = True  # Render HTML log cards in notebooks by default.\n\ndef log_info(label: str, *, advance: int = 1, show_html: bool = SHOW_HTML) -> None:\n    log_info_step(progress_tracker, log, label, advance=advance, show_html=show_html)\n\n\ndef log_warn(label: str, *, advance: int = 1, show_html: bool = SHOW_HTML) -> None:\n    log_warn_step(progress_tracker, log, label, advance=advance, show_html=show_html)\n\n\ndef log_error(label: str, *, advance: int = 1, show_html: bool = SHOW_HTML) -> None:\n    log_error_step(progress_tracker, log, label, advance=advance, show_html=show_html)\n\n\ndef log_end(label: str, *, advance: int = 1, show_html: bool = SHOW_HTML) -> None:\n    log_end_step(progress_tracker, log, label, advance=advance, show_html=show_html)\n\n\ndef show_df(df, n: int = 5) -> None:\n    if \"display\" in globals():\n        display(df)  # type: ignore[name-defined]\n    else:\n        print(preview(df, n=n))\n\n# Set any reusable parameters here\njob_ts = _dt.datetime.now().replace(microsecond=0).isoformat()\nTARGET_COLUMN = \"company\"\nTARGET_VALUES = [\"OpenAI\", \"Alphabet\", \"Microsoft\", \"Amazon\"]\nMAPPING_MODEL = \"o4-mini\"\nRUN_LIVE_MAPPING = False\nWRITE_OUTPUT = False\n",
   "outputs": [],
   "execution_count": null,
   "id": "629fff41"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load configuration\n",
    "\n",
    "Settings are layered in priority order (config/base.yaml -> config/{env}.yaml -> .env -> env vars).\n",
    "Set APP_ENV to local, staging, or prod, and keep secrets in .env or real environment variables.\n"
   ],
   "id": "f4c237bc"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "settings = get_settings()\n",
    "log_info(f\"Loaded settings for env={settings.env}\")\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "8d29ec0f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure LLM credentials\n",
    "\n",
    "Enter credentials below. On Databricks, these widgets populate environment variables used by the mapping helper.\n",
    "Optionally, provide a secret scope and key names to resolve values from Databricks Secrets.\n"
   ],
   "id": "b7f06b3f"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "if \"dbutils\" in globals():\n",
    "    dbutils.widgets.removeAll()\n",
    "    dbutils.widgets.text(\"OPENAI_API_KEY\", \"\", \"OpenAI API Key\")\n",
    "    dbutils.widgets.text(\"AZURE_OPENAI_ENDPOINT\", \"\", \"Azure OpenAI Endpoint (optional)\")\n",
    "    dbutils.widgets.text(\"AZURE_OPENAI_KEY\", \"\", \"Azure OpenAI Key (optional)\")\n",
    "    dbutils.widgets.text(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\", \"Azure OpenAI API Version\")\n",
    "    dbutils.widgets.text(\"LLM_SECRET_SCOPE\", \"\", \"Secret Scope (optional)\")\n",
    "    dbutils.widgets.text(\"SECRET_OPENAI_API_KEY\", \"\", \"Secret Key: OpenAI API Key\")\n",
    "    dbutils.widgets.text(\"SECRET_AZURE_ENDPOINT\", \"\", \"Secret Key: Azure Endpoint\")\n",
    "    dbutils.widgets.text(\"SECRET_AZURE_API_KEY\", \"\", \"Secret Key: Azure API Key\")\n",
    "    dbutils.widgets.text(\"SECRET_AZURE_API_VERSION\", \"\", \"Secret Key: Azure API Version\")\n",
    "\n",
    "    def _widget(name: str) -> str:\n",
    "        return dbutils.widgets.get(name).strip()\n",
    "\n",
    "    scope = _widget(\"LLM_SECRET_SCOPE\")\n",
    "\n",
    "    def _resolve(widget_name: str, secret_widget: str) -> str:\n",
    "        value = _widget(widget_name)\n",
    "        secret_name = _widget(secret_widget) if scope else \"\"\n",
    "        if scope and secret_name:\n",
    "            try:\n",
    "                secret_value = dbutils.secrets.get(scope=scope, key=secret_name)\n",
    "                if secret_value:\n",
    "                    value = secret_value\n",
    "            except Exception as exc:  # noqa: BLE001\n",
    "                print(f\"Warning: unable to read secret '{secret_name}' from scope '{scope}': {exc}\")\n",
    "        return value\n",
    "\n",
    "    openai_key = _resolve(\"OPENAI_API_KEY\", \"SECRET_OPENAI_API_KEY\")\n",
    "    azure_endpoint = _resolve(\"AZURE_OPENAI_ENDPOINT\", \"SECRET_AZURE_ENDPOINT\")\n",
    "    azure_key = _resolve(\"AZURE_OPENAI_KEY\", \"SECRET_AZURE_API_KEY\")\n",
    "    azure_version = _resolve(\"AZURE_OPENAI_API_VERSION\", \"SECRET_AZURE_API_VERSION\") or \"2023-05-15\"\n",
    "else:\n",
    "    openai_key = os.environ.get(\"OPENAI_API_KEY\", \"\").strip()\n",
    "    azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\").strip()\n",
    "    azure_key = os.environ.get(\"AZURE_OPENAI_KEY\", \"\").strip()\n",
    "    azure_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\").strip()\n",
    "\n",
    "if openai_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "if azure_endpoint:\n",
    "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = azure_endpoint\n",
    "if azure_key:\n",
    "    os.environ[\"AZURE_OPENAI_KEY\"] = azure_key\n",
    "if azure_version:\n",
    "    os.environ[\"AZURE_OPENAI_API_VERSION\"] = azure_version\n",
    "\n",
    "provider = \"azure\" if azure_endpoint else \"openai\"\n",
    "if openai_key or azure_key:\n",
    "    log_info(f\"LLM credentials configured for {provider}.\", advance=0)\n",
    "else:\n",
    "    log_warn(\"No LLM credentials found; live mapping will fail without API keys.\", advance=0)\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "c6edb66d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a session\n",
    "\n",
    "Adjust `app_name`, `master`, and configs for your environment.\n"
   ],
   "id": "686b377d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "log_info(\"Starting Spark session...\", advance=0)\n",
    "spark = create_session(\n",
    "    app_name=f\"llm-mapping-template-{settings.env}\",\n",
    "    master=\"local[*]\",\n",
    "    extra_configs={\"spark.some.credential\": \"value\"},\n",
    ")\n",
    "log_info(\"Spark session ready\")\n",
    "spark\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "e11cfff7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start logging\n",
    "\n",
    "Raise Spark log verbosity while you iterate so shuffle and scheduler details show up in the driver logs.\n"
   ],
   "id": "73c81a5a"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "enable_spark_logging(spark, level=settings.logging.level)\n",
    "log_info(f\"Spark logging enabled at {settings.logging.level}.\", advance=0)\n",
    "log_info(\"Logging configured\")\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "dbface47"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load relevant data\n",
    "\n",
    "Declare input locations and load dataframes. Replace the sample with your sources.\n"
   ],
   "id": "bddf0888"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "log_info(\"Loading input data (dummy samples; replace with real sources)...\", advance=0)\n",
    "\n",
    "sample_data = [\n",
    "    Row(id=1, company=\"OpenAI Inc.\"),\n",
    "    Row(id=2, company=\"Alphabet\"),\n",
    "    Row(id=3, company=\"Micro Soft\"),\n",
    "    Row(id=4, company=\"amazon.com\"),\n",
    "    Row(id=5, company=None),\n",
    "]\n",
    "\n",
    "source_df = spark.createDataFrame(sample_data)\n",
    "ensure_columns(source_df, [TARGET_COLUMN])\n",
    "\n",
    "log_info(\"Input data loaded\")\n",
    "show_df(source_df)\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "eb8b80bf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run dry-run mapping\n",
    "\n",
    "Dry-run mode performs exact case-insensitive matching without calling an LLM.\n"
   ],
   "id": "da8527d1"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "log_info(\"Running dry-run mapping...\", advance=0)\n",
    "\n",
    "dry_run_df = map_column_with_llm(\n",
    "    source_df,\n",
    "    column=TARGET_COLUMN,\n",
    "    target_values=TARGET_VALUES,\n",
    "    dry_run=True,\n",
    ")\n",
    "\n",
    "show_df(dry_run_df)\n",
    "log_info(\"Dry-run mapping complete\")\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "b6098835"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run live mapping\n",
    "\n",
    "Set `RUN_LIVE_MAPPING = True` to call the LLM for fuzzy matching.\n"
   ],
   "id": "116e6a2e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if RUN_LIVE_MAPPING:\n",
    "    if not (openai_key or azure_key):\n",
    "        mapped_df = None\n",
    "        log_warn(\"RUN_LIVE_MAPPING=True but no API key found; skipping live mapping.\")\n",
    "    else:\n",
    "        log_info(\"Running live LLM mapping...\", advance=0)\n",
    "        mapped_df = map_column_with_llm(\n",
    "            source_df,\n",
    "            column=TARGET_COLUMN,\n",
    "            target_values=TARGET_VALUES,\n",
    "            model=MAPPING_MODEL,\n",
    "            dry_run=False,\n",
    "            temperature=None,\n",
    "        )\n",
    "        show_df(mapped_df)\n",
    "        log_info(\"Live mapping complete\")\n",
    "else:\n",
    "    mapped_df = None\n",
    "    log_warn(\"RUN_LIVE_MAPPING is False; skipping live LLM calls.\")\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "99f80830"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review mapping metrics\n"
   ],
   "id": "bdfb6a19"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "output_df = mapped_df if mapped_df is not None else dry_run_df\n",
    "ensure_columns(output_df, [TARGET_COLUMN, f\"{TARGET_COLUMN}_mapped\"])\n",
    "\n",
    "mapped_count = output_df.filter(F.col(f\"{TARGET_COLUMN}_mapped\").isNotNull()).count()\n",
    "unmapped_count = output_df.filter(F.col(f\"{TARGET_COLUMN}_mapped\").isNull()).count()\n",
    "\n",
    "log_info(f\"Mapped rows: {mapped_count}\", advance=0)\n",
    "log_info(f\"Unmapped rows: {unmapped_count}\", advance=0)\n",
    "log_info(\"Mapping metrics computed\")\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "1db6ed56"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional write\n",
    "\n",
    "Persist mapped results to storage if needed.\n"
   ],
   "id": "d65c04de"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "output_path = f\"/tmp/spark_fuse/{settings.env}/llm_mapped_{TARGET_COLUMN}\"\n",
    "output_format = \"delta\"\n",
    "\n",
    "def _write_output(df):\n",
    "    if output_format == \"delta\":\n",
    "        df.write.format(\"delta\").mode(\"overwrite\").save(output_path)\n",
    "    else:\n",
    "        df.write.format(output_format).mode(\"overwrite\").save(output_path)\n",
    "\n",
    "if WRITE_OUTPUT:\n",
    "    try:\n",
    "        from delta.tables import DeltaTable  # noqa: F401\n",
    "    except Exception:\n",
    "        output_format = \"parquet\"\n",
    "        log_warn(\"Delta Lake not available; falling back to parquet for write.\", advance=0)\n",
    "\n",
    "    log_info(f\"Writing mapped data to {output_path} (format={output_format})...\", advance=0)\n",
    "    _write_output(output_df)\n",
    "\n",
    "    persisted_df = spark.read.format(output_format).load(output_path)\n",
    "    ensure_columns(persisted_df, [TARGET_COLUMN, f\"{TARGET_COLUMN}_mapped\"])\n",
    "    assert persisted_df.count() > 0, \"Persisted dataset is empty\"\n",
    "\n",
    "    log_info(\"Write complete\")\n",
    "else:\n",
    "    log_warn(\"WRITE_OUTPUT is False; skipping persistence step.\")\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "a192828f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up widgets\n"
   ],
   "id": "ff8ec0b0"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if \"dbutils\" in globals():\n",
    "    dbutils.widgets.removeAll()\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "48c0227c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop session\n",
    "\n",
    "Shut down the session once the job completes.\n"
   ],
   "id": "3d1445ec"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "log_info(\"Stopping Spark session.\", advance=0)\n",
    "spark.stop()\n",
    "log_end(\"Spark session stopped\")\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "bdd28e52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
