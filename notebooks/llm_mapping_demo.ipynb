{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM-Powered Column Mapping Demo\n",
        "\n",
        "This notebook shows how to normalize free-form values in a Spark DataFrame with `map_column_with_llm`. The helper can run in dry-run mode (no external calls) or call OpenAI/Azure OpenAI with retries, caching, and usage tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Databricks notebooks normally provide a SparkSession named `spark`.\n",
        "# This fallback ensures local execution still works.\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark.sql(\"SET spark.sql.shuffle.partitions=8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure LLM Credentials\n",
        "\n",
        "Enter your credentials below. On Databricks these widgets populate environment variables used by the mapping helper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if \"dbutils\" in globals():\n",
          "    dbutils.widgets.removeAll()\n",
          "    dbutils.widgets.text(\"OPENAI_API_KEY\", \"\", \"OpenAI API Key\")\n",
          "    dbutils.widgets.text(\"AZURE_OPENAI_ENDPOINT\", \"\", \"Azure OpenAI Endpoint (optional)\")\n",
          "    dbutils.widgets.text(\"AZURE_OPENAI_KEY\", \"\", \"Azure OpenAI Key (optional)\")\n",
          "    dbutils.widgets.text(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\", \"Azure OpenAI API Version\")\n",
          "\n",
          "    openai_key = dbutils.widgets.get(\"OPENAI_API_KEY\")\n",
          "    azure_endpoint = dbutils.widgets.get(\"AZURE_OPENAI_ENDPOINT\")\n",
          "    azure_key = dbutils.widgets.get(\"AZURE_OPENAI_KEY\")\n",
          "    azure_version = dbutils.widgets.get(\"AZURE_OPENAI_API_VERSION\")\n",
          "else:\n",
          "    openai_key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
          "    azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\")\n",
          "    azure_key = os.environ.get(\"AZURE_OPENAI_KEY\", \"\")\n",
          "    azure_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\")\n",
          "\n",
          "if openai_key:\n",
          "    os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
          "if azure_endpoint:\n",
          "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = azure_endpoint\n",
          "if azure_key:\n",
          "    os.environ[\"AZURE_OPENAI_KEY\"] = azure_key\n",
          "if azure_version:\n",
          "    os.environ[\"AZURE_OPENAI_API_VERSION\"] = azure_version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a Sample DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "sample_data = [\n",
        "    Row(id=1, company=\"OpenAI Inc.\"),\n",
        "    Row(id=2, company=\"Alphabet\"),\n",
        "    Row(id=3, company=\"Micro Soft\"),\n",
        "    Row(id=4, company=\"amazon.com\"),\n",
        "    Row(id=5, company=None),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(sample_data)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Dry-Run Mapping\n",
        "\n",
        "Dry-run mode performs exact case-insensitive matching without calling an LLM. Use this to estimate how many rows already match your target list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spark_fuse.utils.transformations import map_column_with_llm\n",
        "\n",
        "target_companies = [\"OpenAI\", \"Alphabet\", \"Microsoft\", \"Amazon\"]\n",
        "\n",
        "dry_run_df = map_column_with_llm(\n",
        "    df,\n",
        "    column=\"company\",\n",
        "    target_values=target_companies,\n",
        "    dry_run=True,\n",
        ")\n",
        "display(dry_run_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Live Mapping\n",
        "\n",
        "With credentials configured, set `dry_run=False` to call the LLM for fuzzy matching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapped_df = map_column_with_llm(\n",
        "    df,\n",
        "    column=\"company\",\n",
        "    target_values=target_companies,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    dry_run=False,\n",
        ")\n",
        "display(mapped_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Review Mapping Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapped_count = mapped_df.filter(\"company_mapped IS NOT NULL\").count()\n",
        "unmapped_count = mapped_df.filter(\"company_mapped IS NULL\").count()\n",
        "\n",
        "print(f\"Mapped rows: {mapped_count}\")\n",
        "print(f\"Unmapped rows: {unmapped_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean Up Widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if \"dbutils\" in globals():\n",
        "    dbutils.widgets.removeAll()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
