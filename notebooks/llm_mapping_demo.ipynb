{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM-Powered Column Mapping Demo\n",
        "\n",
        "This notebook shows how to normalize free-form values in a Spark DataFrame with `map_column_with_llm`. The helper can run in dry-run mode (no external calls) or call OpenAI/Azure OpenAI with retries, caching, and usage tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Databricks notebooks normally provide a SparkSession named `spark`.\n",
        "# This fallback ensures local execution still works.\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark.sql(\"SET spark.sql.shuffle.partitions=8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "repo_root = os.path.abspath('..')\n",
        "src_path = os.path.join(repo_root, 'src')\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "print('Added to sys.path:', src_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure LLM Credentials\n",
        "\n",
        "Enter your credentials below. On Databricks these widgets populate environment variables used by the mapping helper. Optionally, provide a secret scope and key names to resolve values from Databricks Secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if \"dbutils\" in globals():\n",
        "    dbutils.widgets.removeAll()\n",
        "    dbutils.widgets.text(\"OPENAI_API_KEY\", \"\", \"OpenAI API Key\")\n",
        "    dbutils.widgets.text(\"AZURE_OPENAI_ENDPOINT\", \"\", \"Azure OpenAI Endpoint (optional)\")\n",
        "    dbutils.widgets.text(\"AZURE_OPENAI_KEY\", \"\", \"Azure OpenAI Key (optional)\")\n",
        "    dbutils.widgets.text(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\", \"Azure OpenAI API Version\")\n",
        "    dbutils.widgets.text(\"LLM_SECRET_SCOPE\", \"\", \"Secret Scope (optional)\")\n",
        "    dbutils.widgets.text(\"SECRET_OPENAI_API_KEY\", \"\", \"Secret Key: OpenAI API Key\")\n",
        "    dbutils.widgets.text(\"SECRET_AZURE_ENDPOINT\", \"\", \"Secret Key: Azure Endpoint\")\n",
        "    dbutils.widgets.text(\"SECRET_AZURE_API_KEY\", \"\", \"Secret Key: Azure API Key\")\n",
        "    dbutils.widgets.text(\"SECRET_AZURE_API_VERSION\", \"\", \"Secret Key: Azure API Version\")\n",
        "\n",
        "    def _widget(name: str) -> str:\n",
        "        return dbutils.widgets.get(name).strip()\n",
        "\n",
        "    scope = _widget(\"LLM_SECRET_SCOPE\")\n",
        "\n",
        "    def _resolve(widget_name: str, secret_widget: str) -> str:\n",
        "        value = _widget(widget_name)\n",
        "        secret_name = _widget(secret_widget) if scope else \"\"\n",
        "        if scope and secret_name:\n",
        "            try:\n",
        "                secret_value = dbutils.secrets.get(scope=scope, key=secret_name)\n",
        "                if secret_value:\n",
        "                    value = secret_value\n",
        "            except Exception as exc:  # noqa: BLE001\n",
        "                print(f\"Warning: unable to read secret '{secret_name}' from scope '{scope}': {exc}\")\n",
        "        return value\n",
        "\n",
        "    openai_key = _resolve(\"OPENAI_API_KEY\", \"SECRET_OPENAI_API_KEY\")\n",
        "    azure_endpoint = _resolve(\"AZURE_OPENAI_ENDPOINT\", \"SECRET_AZURE_ENDPOINT\")\n",
        "    azure_key = _resolve(\"AZURE_OPENAI_KEY\", \"SECRET_AZURE_API_KEY\")\n",
        "    azure_version = _resolve(\"AZURE_OPENAI_API_VERSION\", \"SECRET_AZURE_API_VERSION\") or \"2023-05-15\"\n",
        "else:\n",
        "    openai_key = os.environ.get(\"OPENAI_API_KEY\", \"\").strip()\n",
        "    azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\").strip()\n",
        "    azure_key = os.environ.get(\"AZURE_OPENAI_KEY\", \"\").strip()\n",
        "    azure_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\").strip()\n",
        "\n",
        "if openai_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "if azure_endpoint:\n",
        "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = azure_endpoint\n",
        "if azure_key:\n",
        "    os.environ[\"AZURE_OPENAI_KEY\"] = azure_key\n",
        "if azure_version:\n",
        "    os.environ[\"AZURE_OPENAI_API_VERSION\"] = azure_version\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a Sample DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "sample_data = [\n",
        "    Row(id=1, company=\"OpenAI Inc.\"),\n",
        "    Row(id=2, company=\"Alphabet\"),\n",
        "    Row(id=3, company=\"Micro Soft\"),\n",
        "    Row(id=4, company=\"amazon.com\"),\n",
        "    Row(id=5, company=None),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(sample_data)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Dry-Run Mapping\n",
        "\n",
        "Dry-run mode performs exact case-insensitive matching without calling an LLM. Use this to estimate how many rows already match your target list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spark_fuse.utils.transformations import map_column_with_llm\n",
        "\n",
        "target_companies = [\"OpenAI\", \"Alphabet\", \"Microsoft\", \"Amazon\"]\n",
        "\n",
        "dry_run_df = map_column_with_llm(\n",
        "    df,\n",
        "    column=\"company\",\n",
        "    target_values=target_companies,\n",
        "    dry_run=True,\n",
        "    temperature=0.0,\n",
        ")\n",
        "display(dry_run_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Live Mapping\n",
        "\n",
        "With credentials configured, set `dry_run=False` to call the LLM for fuzzy matching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapped_df = map_column_with_llm(\n",
        "    df,\n",
        "    column=\"company\",\n",
        "    target_values=target_companies,\n",
        "    model=\"o4-mini\",\n",
        "    dry_run=False,\n",
        "    temperature=None,\n",
        ")\n",
        "display(mapped_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Review Mapping Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapped_count = mapped_df.filter(\"company_mapped IS NOT NULL\").count()\n",
        "unmapped_count = mapped_df.filter(\"company_mapped IS NULL\").count()\n",
        "\n",
        "print(f\"Mapped rows: {mapped_count}\")\n",
        "print(f\"Unmapped rows: {unmapped_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean Up Widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if \"dbutils\" in globals():\n",
        "    dbutils.widgets.removeAll()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
